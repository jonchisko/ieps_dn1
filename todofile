Jon:
    1. dodaj, da zavrže linke, ki NE vsebujejo gov.si ( done, not tested)
    2. še eno isto funkcijo za v paralel ( in progress )
    3. dodaj checkgoodurl, ceprazen disalow, guci

Domen: robot.txt
For each domain respect the robots.txt file if it exists. Correctly respect the commands User-agent,
Allow, Disallow, Crawl-delay and Sitemap. If a sitemap is defined, all the URLs that are defined within
it, should be added to the frontier.
Make sure to respect robots.txt as sites that define special crawling rules often contain spider traps.



:::::::Vprasanja::::::::
- Ce imamo search bar - ali moramo iskati po searchu ("querijat")
- Kako je z vecnitanjem s seleniumom, ali lahko sekvencno getam in parsam paralelno
- Kako lahko preverimo ali JS ali ne
